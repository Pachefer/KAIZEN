{
  "titulo": "Sistema de Mejora Continua Azure - Automatización y Optimización",
  "descripcion": "Sistema completo de mejora continua con automatización, monitoreo y optimización",
  "automatizacion": {
    "resource_monitoring": "\n```python\n# Script de monitoreo automático de recursos\nimport azure.mgmt.monitor as monitor\nfrom azure.identity import DefaultAzureCredential\nimport schedule\nimport time\n\nclass AzureResourceMonitor:\n    def __init__(self):\n        self.credential = DefaultAzureCredential()\n        self.monitor_client = monitor.MonitorManagementClient(\n            self.credential, \n            subscription_id=\"your-subscription-id\"\n        )\n    \n    def check_resource_health(self):\n        # Verificar salud de recursos críticos\n        resources = self.get_critical_resources()\n        \n        for resource in resources:\n            metrics = self.get_resource_metrics(resource.id)\n            if self.is_resource_unhealthy(metrics):\n                self.send_alert(f\"Resource {resource.name} is unhealthy\")\n    \n    def get_critical_resources(self):\n        # Obtener recursos críticos (VMs, databases, etc.)\n        pass\n    \n    def get_resource_metrics(self, resource_id):\n        # Obtener métricas del recurso\n        pass\n    \n    def is_resource_unhealthy(self, metrics):\n        # Evaluar si el recurso está saludable\n        pass\n    \n    def send_alert(self, message):\n        # Enviar alerta\n        print(f\"ALERT: {message}\")\n\n# Configurar monitoreo cada 15 minutos\nmonitor = AzureResourceMonitor()\nschedule.every(15).minutes.do(monitor.check_resource_health)\n\nwhile True:\n    schedule.run_pending()\n    time.sleep(60)\n```",
    "cost_optimization": "\n```python\n# Script de optimización automática de costos\nimport azure.mgmt.compute as compute\nimport azure.mgmt.monitor as monitor\nfrom azure.identity import DefaultAzureCredential\nimport datetime\n\nclass AzureCostOptimizer:\n    def __init__(self):\n        self.credential = DefaultAzureCredential()\n        self.compute_client = compute.ComputeManagementClient(\n            self.credential, \n            subscription_id=\"your-subscription-id\"\n        )\n        self.monitor_client = monitor.MonitorManagementClient(\n            self.credential, \n            subscription_id=\"your-subscription-id\"\n        )\n    \n    def analyze_vm_usage(self):\n        vms = self.compute_client.virtual_machines.list_all()\n        \n        for vm in vms:\n            usage = self.get_vm_usage(vm.id)\n            recommendation = self.get_optimization_recommendation(usage)\n            \n            if recommendation:\n                self.apply_optimization(vm, recommendation)\n    \n    def get_vm_usage(self, vm_id):\n        # Obtener métricas de uso de la VM\n        end_time = datetime.datetime.utcnow()\n        start_time = end_time - datetime.timedelta(days=7)\n        \n        metrics = self.monitor_client.metrics.list(\n            vm_id,\n            timespan=f\"{start_time.isoformat()}/{end_time.isoformat()}\",\n            interval='PT1H',\n            metricnames='Percentage CPU,Percentage Memory',\n            aggregation='Average'\n        )\n        \n        return metrics\n    \n    def get_optimization_recommendation(self, usage):\n        # Analizar uso y generar recomendaciones\n        avg_cpu = self.calculate_average_cpu(usage)\n        avg_memory = self.calculate_average_memory(usage)\n        \n        if avg_cpu < 20 and avg_memory < 30:\n            return \"downsize\"\n        elif avg_cpu > 80 or avg_memory > 80:\n            return \"upsize\"\n        \n        return None\n    \n    def apply_optimization(self, vm, recommendation):\n        # Aplicar optimización\n        if recommendation == \"downsize\":\n            self.downsize_vm(vm)\n        elif recommendation == \"upsize\":\n            self.upsize_vm(vm)\n    \n    def downsize_vm(self, vm):\n        # Reducir tamaño de VM\n        print(f\"Downsizing VM: {vm.name}\")\n    \n    def upsize_vm(self, vm):\n        # Aumentar tamaño de VM\n        print(f\"Upsizing VM: {vm.name}\")\n\n# Ejecutar optimización diariamente\noptimizer = AzureCostOptimizer()\noptimizer.analyze_vm_usage()\n```",
    "security_automation": "\n```python\n# Script de automatización de seguridad\nimport azure.mgmt.security as security\nimport azure.mgmt.keyvault as keyvault\nfrom azure.identity import DefaultAzureCredential\nimport datetime\n\nclass AzureSecurityAutomation:\n    def __init__(self):\n        self.credential = DefaultAzureCredential()\n        self.security_client = security.SecurityCenter(\n            self.credential, \n            subscription_id=\"your-subscription-id\"\n        )\n        self.keyvault_client = keyvault.KeyVaultManagementClient(\n            self.credential, \n            subscription_id=\"your-subscription-id\"\n        )\n    \n    def run_security_checks(self):\n        # Ejecutar verificaciones de seguridad\n        self.check_vulnerabilities()\n        self.check_compliance()\n        self.rotate_secrets()\n        self.review_access()\n    \n    def check_vulnerabilities(self):\n        # Verificar vulnerabilidades\n        assessments = self.security_client.assessments.list()\n        \n        for assessment in assessments:\n            if assessment.status.code == \"Unhealthy\":\n                self.create_security_ticket(assessment)\n    \n    def check_compliance(self):\n        # Verificar cumplimiento\n        compliance_results = self.security_client.compliance.list()\n        \n        for compliance in compliance_results:\n            if compliance.score < 80:\n                self.send_compliance_alert(compliance)\n    \n    def rotate_secrets(self):\n        # Rotar secretos automáticamente\n        vaults = self.keyvault_client.vaults.list()\n        \n        for vault in vaults:\n            secrets = self.get_vault_secrets(vault.name)\n            \n            for secret in secrets:\n                if self.should_rotate_secret(secret):\n                    self.rotate_secret(vault.name, secret.name)\n    \n    def review_access(self):\n        # Revisar acceso de usuarios\n        users = self.get_active_users()\n        \n        for user in users:\n            if self.should_review_access(user):\n                self.send_access_review_request(user)\n    \n    def create_security_ticket(self, assessment):\n        # Crear ticket de seguridad\n        print(f\"Security ticket created for: {assessment.display_name}\")\n    \n    def send_compliance_alert(self, compliance):\n        # Enviar alerta de cumplimiento\n        print(f\"Compliance alert: {compliance.name} score: {compliance.score}\")\n    \n    def rotate_secret(self, vault_name, secret_name):\n        # Rotar secreto\n        print(f\"Rotating secret: {secret_name} in vault: {vault_name}\")\n    \n    def send_access_review_request(self, user):\n        # Enviar solicitud de revisión de acceso\n        print(f\"Access review requested for user: {user.name}\")\n\n# Ejecutar verificaciones de seguridad semanalmente\nsecurity_automation = AzureSecurityAutomation()\nsecurity_automation.run_security_checks()\n```",
    "backup_automation": "\n```python\n# Script de automatización de respaldos\nimport azure.mgmt.recoveryservices as recoveryservices\nimport azure.mgmt.recoveryservicesbackup as backup\nfrom azure.identity import DefaultAzureCredential\nimport datetime\n\nclass AzureBackupAutomation:\n    def __init__(self):\n        self.credential = DefaultAzureCredential()\n        self.backup_client = backup.RecoveryServicesBackupClient(\n            self.credential, \n            subscription_id=\"your-subscription-id\"\n        )\n        self.recovery_client = recoveryservices.RecoveryServicesClient(\n            self.credential, \n            subscription_id=\"your-subscription-id\"\n        )\n    \n    def manage_backups(self):\n        # Gestionar respaldos automáticamente\n        self.create_backups()\n        self.verify_backups()\n        self.cleanup_old_backups()\n        self.test_restore()\n    \n    def create_backups(self):\n        # Crear respaldos programados\n        backup_policies = self.get_backup_policies()\n        \n        for policy in backup_policies:\n            if self.should_create_backup(policy):\n                self.execute_backup(policy)\n    \n    def verify_backups(self):\n        # Verificar integridad de respaldos\n        backups = self.get_recent_backups()\n        \n        for backup in backups:\n            if not self.verify_backup_integrity(backup):\n                self.send_backup_failure_alert(backup)\n    \n    def cleanup_old_backups(self):\n        # Limpiar respaldos antiguos\n        old_backups = self.get_old_backups()\n        \n        for backup in old_backups:\n            if self.should_delete_backup(backup):\n                self.delete_backup(backup)\n    \n    def test_restore(self):\n        # Probar restauración de respaldos\n        test_backups = self.get_test_backups()\n        \n        for backup in test_backups:\n            if self.should_test_restore(backup):\n                self.execute_test_restore(backup)\n    \n    def should_create_backup(self, policy):\n        # Determinar si se debe crear respaldo\n        last_backup = self.get_last_backup(policy)\n        return datetime.datetime.now() - last_backup > datetime.timedelta(days=1)\n    \n    def execute_backup(self, policy):\n        # Ejecutar respaldo\n        print(f\"Executing backup for policy: {policy.name}\")\n    \n    def verify_backup_integrity(self, backup):\n        # Verificar integridad del respaldo\n        return True  # Simulado\n    \n    def send_backup_failure_alert(self, backup):\n        # Enviar alerta de fallo de respaldo\n        print(f\"Backup failure alert for: {backup.name}\")\n    \n    def should_delete_backup(self, backup):\n        # Determinar si se debe eliminar respaldo\n        return backup.age > datetime.timedelta(days=30)\n    \n    def delete_backup(self, backup):\n        # Eliminar respaldo\n        print(f\"Deleting old backup: {backup.name}\")\n    \n    def should_test_restore(self, backup):\n        # Determinar si se debe probar restauración\n        return backup.last_test_restore < datetime.datetime.now() - datetime.timedelta(days=7)\n    \n    def execute_test_restore(self, backup):\n        # Ejecutar prueba de restauración\n        print(f\"Testing restore for backup: {backup.name}\")\n\n# Ejecutar gestión de respaldos diariamente\nbackup_automation = AzureBackupAutomation()\nbackup_automation.manage_backups()\n```"
  },
  "dashboards": {
    "performance_dashboard": "\n```json\n{\n  \"dashboard\": {\n    \"name\": \"Azure Performance Dashboard\",\n    \"widgets\": [\n      {\n        \"type\": \"metric\",\n        \"name\": \"CPU Usage\",\n        \"query\": \"Perf | where ObjectName == 'Processor' | where CounterName == '% Processor Time' | summarize avg(CounterValue) by bin(TimeGenerated, 5m)\",\n        \"visualization\": \"timechart\"\n      },\n      {\n        \"type\": \"metric\",\n        \"name\": \"Memory Usage\",\n        \"query\": \"Perf | where ObjectName == 'Memory' | where CounterName == '% Committed Bytes In Use' | summarize avg(CounterValue) by bin(TimeGenerated, 5m)\",\n        \"visualization\": \"timechart\"\n      },\n      {\n        \"type\": \"metric\",\n        \"name\": \"Disk I/O\",\n        \"query\": \"Perf | where ObjectName == 'LogicalDisk' | where CounterName == 'Disk Reads/sec' | summarize avg(CounterValue) by bin(TimeGenerated, 5m)\",\n        \"visualization\": \"timechart\"\n      },\n      {\n        \"type\": \"metric\",\n        \"name\": \"Network Usage\",\n        \"query\": \"Perf | where ObjectName == 'Network Interface' | where CounterName == 'Bytes Total/sec' | summarize avg(CounterValue) by bin(TimeGenerated, 5m)\",\n        \"visualization\": \"timechart\"\n      }\n    ]\n  }\n}\n```",
    "cost_dashboard": "\n```json\n{\n  \"dashboard\": {\n    \"name\": \"Azure Cost Dashboard\",\n    \"widgets\": [\n      {\n        \"type\": \"cost\",\n        \"name\": \"Daily Cost Trend\",\n        \"query\": \"Usage | where TimeGenerated > ago(30d) | summarize sum(Quantity) by bin(TimeGenerated, 1d), ResourceType | render timechart\",\n        \"visualization\": \"timechart\"\n      },\n      {\n        \"type\": \"cost\",\n        \"name\": \"Cost by Resource Type\",\n        \"query\": \"Usage | where TimeGenerated > ago(7d) | summarize sum(Quantity) by ResourceType | render piechart\",\n        \"visualization\": \"piechart\"\n      },\n      {\n        \"type\": \"cost\",\n        \"name\": \"Top Expensive Resources\",\n        \"query\": \"Usage | where TimeGenerated > ago(7d) | summarize sum(Quantity) by ResourceId | top 10 by sum_Quantity | render barchart\",\n        \"visualization\": \"barchart\"\n      },\n      {\n        \"type\": \"cost\",\n        \"name\": \"Cost Optimization Opportunities\",\n        \"query\": \"Usage | where TimeGenerated > ago(7d) | where ResourceType == 'virtualMachines' | summarize avg(Quantity) by ResourceId | where avg_Quantity < 20\",\n        \"visualization\": \"table\"\n      }\n    ]\n  }\n}\n```",
    "security_dashboard": "\n```json\n{\n  \"dashboard\": {\n    \"name\": \"Azure Security Dashboard\",\n    \"widgets\": [\n      {\n        \"type\": \"security\",\n        \"name\": \"Security Score\",\n        \"query\": \"SecurityEvent | where TimeGenerated > ago(7d) | summarize count() by EventID | render gauge\",\n        \"visualization\": \"gauge\"\n      },\n      {\n        \"type\": \"security\",\n        \"name\": \"Failed Login Attempts\",\n        \"query\": \"SecurityEvent | where TimeGenerated > ago(24h) | where EventID == 4625 | summarize count() by bin(TimeGenerated, 1h) | render timechart\",\n        \"visualization\": \"timechart\"\n      },\n      {\n        \"type\": \"security\",\n        \"name\": \"Vulnerability Assessment\",\n        \"query\": \"SecurityRecommendation | where TimeGenerated > ago(7d) | summarize count() by RecommendationType | render barchart\",\n        \"visualization\": \"barchart\"\n      },\n      {\n        \"type\": \"security\",\n        \"name\": \"Compliance Status\",\n        \"query\": \"ComplianceAssessment | where TimeGenerated > ago(7d) | summarize avg(Score) by ComplianceStandard | render table\",\n        \"visualization\": \"table\"\n      }\n    ]\n  }\n}\n```"
  },
  "workflows": {
    "incident_response": "\n```yaml\n# Flujo de trabajo de respuesta a incidentes\nname: Incident Response Workflow\ndescription: Workflow automatizado para respuesta a incidentes de Azure\n\ntriggers:\n  - name: high_cpu_alert\n    condition: CPU > 90% for 5 minutes\n    actions:\n      - scale_out_vm\n      - send_alert\n      - create_incident_ticket\n  \n  - name: security_breach\n    condition: Failed login attempts > 10 in 1 hour\n    actions:\n      - block_ip_address\n      - notify_security_team\n      - create_security_incident\n  \n  - name: cost_spike\n    condition: Daily cost > 150% of average\n    actions:\n      - analyze_cost_breakdown\n      - send_cost_alert\n      - review_resource_usage\n\nactions:\n  scale_out_vm:\n    type: azure_automation\n    script: scale_vm.ps1\n    parameters:\n      resource_group: \"{{ resource_group }}\"\n      vm_name: \"{{ vm_name }}\"\n      scale_factor: 1.5\n  \n  send_alert:\n    type: notification\n    channel: teams\n    message: \"Alert: {{ alert_message }}\"\n  \n  create_incident_ticket:\n    type: service_now\n    template: incident_template.json\n    data:\n      priority: \"{{ priority }}\"\n      description: \"{{ description }}\"\n  \n  block_ip_address:\n    type: azure_automation\n    script: block_ip.ps1\n    parameters:\n      ip_address: \"{{ source_ip }}\"\n      duration: \"1 hour\"\n  \n  notify_security_team:\n    type: notification\n    channel: email\n    recipients: [\"security@company.com\"]\n    subject: \"Security Incident Detected\"\n  \n  analyze_cost_breakdown:\n    type: azure_automation\n    script: analyze_cost.ps1\n    parameters:\n      time_range: \"24h\"\n  \n  review_resource_usage:\n    type: azure_automation\n    script: review_resources.ps1\n    parameters:\n      resource_types: [\"virtualMachines\", \"storageAccounts\"]\n```\n",
    "deployment_automation": "\n```yaml\n# Flujo de trabajo de despliegue automatizado\nname: Automated Deployment Workflow\ndescription: Workflow para despliegue automatizado con CI/CD\n\nstages:\n  - name: build\n    steps:\n      - name: code_analysis\n        type: static_analysis\n        tools: [\"sonarqube\", \"eslint\"]\n      \n      - name: unit_tests\n        type: testing\n        framework: \"jest\"\n        coverage_threshold: 80\n      \n      - name: security_scan\n        type: security_scanning\n        tools: [\"snyk\", \"dependency-check\"]\n      \n      - name: build_artifacts\n        type: build\n        platform: \"docker\"\n        output: \"container_registry\"\n  \n  - name: test\n    environment: \"staging\"\n    steps:\n      - name: deploy_staging\n        type: deployment\n        method: \"blue_green\"\n      \n      - name: integration_tests\n        type: testing\n        framework: \"cypress\"\n      \n      - name: performance_tests\n        type: testing\n        framework: \"k6\"\n        thresholds:\n          response_time: \"200ms\"\n          error_rate: \"1%\"\n      \n      - name: security_tests\n        type: testing\n        framework: \"zap\"\n      \n      - name: user_acceptance_tests\n        type: testing\n        framework: \"selenium\"\n  \n  - name: deploy\n    environment: \"production\"\n    steps:\n      - name: pre_deployment_checks\n        type: validation\n        checks:\n          - resource_availability\n          - cost_impact\n          - security_compliance\n      \n      - name: deploy_production\n        type: deployment\n        method: \"rolling_update\"\n        rollback_enabled: true\n      \n      - name: post_deployment_validation\n        type: validation\n        checks:\n          - health_checks\n          - performance_metrics\n          - security_scan\n      \n      - name: monitoring_setup\n        type: configuration\n        tools:\n          - application_insights\n          - log_analytics\n          - alert_rules\n\nrollback:\n  triggers:\n    - health_check_failure\n    - performance_degradation\n    - security_vulnerability\n  \n  actions:\n    - revert_deployment\n    - notify_team\n    - create_incident\n```\n",
    "optimization_workflow": "\n```yaml\n# Flujo de trabajo de optimización continua\nname: Continuous Optimization Workflow\ndescription: Workflow para optimización automática de recursos\n\nschedules:\n  - name: daily_optimization\n    frequency: \"daily\"\n    time: \"02:00 UTC\"\n  \n  - name: weekly_review\n    frequency: \"weekly\"\n    day: \"monday\"\n    time: \"09:00 UTC\"\n\ntasks:\n  - name: resource_analysis\n    type: analysis\n    scope: \"all_resources\"\n    metrics:\n      - cpu_usage\n      - memory_usage\n      - disk_io\n      - network_usage\n      - cost_performance\n    \n  - name: performance_optimization\n    type: optimization\n    conditions:\n      - cpu_usage > 80% for 1 hour\n      - memory_usage > 85% for 1 hour\n      - response_time > 500ms\n    actions:\n      - scale_up_resources\n      - optimize_queries\n      - add_caching\n    \n  - name: cost_optimization\n    type: optimization\n    conditions:\n      - cost_increase > 20% from baseline\n      - resource_utilization < 30%\n      - unused_resources_detected\n    actions:\n      - scale_down_resources\n      - delete_unused_resources\n      - switch_to_reserved_instances\n    \n  - name: security_optimization\n    type: optimization\n    conditions:\n      - security_score < 80\n      - vulnerabilities_detected\n      - compliance_violations\n    actions:\n      - apply_security_patches\n      - update_access_policies\n      - enable_additional_security_features\n\nreports:\n  - name: optimization_summary\n    frequency: \"weekly\"\n    content:\n      - resource_utilization_summary\n      - cost_savings_achieved\n      - performance_improvements\n      - security_enhancements\n      - recommendations\n    \n  - name: executive_dashboard\n    frequency: \"monthly\"\n    content:\n      - cost_trends\n      - performance_metrics\n      - security_status\n      - compliance_score\n      - optimization_opportunities\n```\n"
  },
  "metricas": {
    "performance_metrics": "\n```python\n# Recolección de métricas de rendimiento\nimport psutil\nimport time\nimport json\nfrom datetime import datetime\nfrom azure.monitor.ingestion import LogsIngestionClient\nfrom azure.identity import DefaultAzureCredential\n\nclass PerformanceMetricsCollector:\n    def __init__(self):\n        self.credential = DefaultAzureCredential()\n        self.logs_client = LogsIngestionClient(\n            endpoint=\"https://your-workspace.ingest.monitor.azure.com\",\n            credential=self.credential\n        )\n        self.workspace_id = \"your-workspace-id\"\n        self.table_name = \"PerformanceMetrics\"\n    \n    def collect_system_metrics(self):\n        # Recolecta métricas del sistema\n        metrics = {\n            \"timestamp\": datetime.utcnow().isoformat(),\n            \"cpu_percent\": psutil.cpu_percent(interval=1),\n            \"memory_percent\": psutil.virtual_memory().percent,\n            \"disk_usage_percent\": psutil.disk_usage('/').percent,\n            \"network_io\": self.get_network_io(),\n            \"process_count\": len(psutil.pids())\n        }\n        \n        return metrics\n    \n    def get_network_io(self):\n        # Obtiene estadísticas de red\n        net_io = psutil.net_io_counters()\n        return {\n            \"bytes_sent\": net_io.bytes_sent,\n            \"bytes_recv\": net_io.bytes_recv,\n            \"packets_sent\": net_io.packets_sent,\n            \"packets_recv\": net_io.packets_recv\n        }\n    \n    def send_metrics(self, metrics):\n        # Envía métricas a Azure Monitor\n        try:\n            self.logs_client.upload(\n                rule_id=self.workspace_id,\n                stream_name=self.table_name,\n                logs=[metrics]\n            )\n            print(f\"Metrics sent successfully: {metrics['timestamp']}\")\n        except Exception as e:\n            print(f\"Error sending metrics: {e}\")\n    \n    def run_collection(self, interval_seconds=60):\n        # Ejecuta recolección continua de métricas\n        print(\"Starting performance metrics collection...\")\n        \n        while True:\n            try:\n                metrics = self.collect_system_metrics()\n                self.send_metrics(metrics)\n                time.sleep(interval_seconds)\n            except KeyboardInterrupt:\n                print(\"Stopping metrics collection...\")\n                break\n            except Exception as e:\n                print(f\"Error in metrics collection: {e}\")\n                time.sleep(interval_seconds)\n\n# Ejecutar recolector de métricas\ncollector = PerformanceMetricsCollector()\ncollector.run_collection()\n```",
    "cost_metrics": "\n```python\n# Recolección de métricas de costo\nfrom azure.mgmt.consumption import ConsumptionManagementClient\nfrom azure.identity import DefaultAzureCredential\nfrom datetime import datetime, timedelta\nimport json\n\nclass CostMetricsCollector:\n    def __init__(self):\n        self.credential = DefaultAzureCredential()\n        self.consumption_client = ConsumptionManagementClient(\n            self.credential, \n            subscription_id=\"your-subscription-id\"\n        )\n    \n    def collect_cost_metrics(self):\n        # Recolecta métricas de costo\n        end_date = datetime.now()\n        start_date = end_date - timedelta(days=30)\n        \n        usage_details = self.consumption_client.usage_details.list(\n            scope=f\"/subscriptions/your-subscription-id\",\n            filter=f\"usageStart ge '{start_date.isoformat()}' and usageEnd le '{end_date.isoformat()}'\"\n        )\n        \n        cost_data = {\n            \"timestamp\": datetime.utcnow().isoformat(),\n            \"daily_costs\": {},\n            \"resource_type_costs\": {},\n            \"total_cost\": 0\n        }\n        \n        for usage in usage_details:\n            date = usage.usage_start.date().isoformat()\n            cost = float(usage.cost)\n            resource_type = usage.consumed_service\n            \n            # Acumular costos diarios\n            if date not in cost_data[\"daily_costs\"]:\n                cost_data[\"daily_costs\"][date] = 0\n            cost_data[\"daily_costs\"][date] += cost\n            \n            # Acumular costos por tipo de recurso\n            if resource_type not in cost_data[\"resource_type_costs\"]:\n                cost_data[\"resource_type_costs\"][resource_type] = 0\n            cost_data[\"resource_type_costs\"][resource_type] += cost\n            \n            cost_data[\"total_cost\"] += cost\n        \n        return cost_data\n    \n    def analyze_cost_trends(self, cost_data):\n        # Analiza tendencias de costo\n        daily_costs = list(cost_data[\"daily_costs\"].values())\n        \n        if len(daily_costs) >= 7:\n            recent_avg = sum(daily_costs[-7:]) / 7\n            previous_avg = sum(daily_costs[-14:-7]) / 7\n            \n            trend = {\n                \"recent_average\": recent_avg,\n                \"previous_average\": previous_avg,\n                \"change_percentage\": ((recent_avg - previous_avg) / previous_avg) * 100,\n                \"trend\": \"increasing\" if recent_avg > previous_avg else \"decreasing\"\n            }\n            \n            return trend\n        \n        return None\n    \n    def generate_cost_recommendations(self, cost_data, trends):\n        # Genera recomendaciones de optimización de costo\n        recommendations = []\n        \n        # Análisis de recursos costosos\n        for resource_type, cost in cost_data[\"resource_type_costs\"].items():\n            if cost > cost_data[\"total_cost\"] * 0.2:  # Más del 20% del costo total\n                recommendations.append({\n                    \"type\": \"high_cost_resource\",\n                    \"resource_type\": resource_type,\n                    \"cost\": cost,\n                    \"percentage\": (cost / cost_data[\"total_cost\"]) * 100,\n                    \"suggestion\": f\"Review {resource_type} usage and consider optimization\"\n                })\n        \n        # Análisis de tendencias\n        if trends and trends[\"change_percentage\"] > 20:\n            recommendations.append({\n                \"type\": \"cost_spike\",\n                \"change_percentage\": trends[\"change_percentage\"],\n                \"suggestion\": \"Investigate recent cost increase\"\n            })\n        \n        return recommendations\n    \n    def send_cost_report(self, cost_data, trends, recommendations):\n        # Envía reporte de costos\n        report = {\n            \"timestamp\": datetime.utcnow().isoformat(),\n            \"cost_data\": cost_data,\n            \"trends\": trends,\n            \"recommendations\": recommendations\n        }\n        \n        # Enviar a Azure Monitor o sistema de alertas\n        print(json.dumps(report, indent=2))\n    \n    def run_cost_analysis(self):\n        # Ejecuta análisis completo de costos\n        print(\"Starting cost analysis...\")\n        \n        cost_data = self.collect_cost_metrics()\n        trends = self.analyze_cost_trends(cost_data)\n        recommendations = self.generate_cost_recommendations(cost_data, trends)\n        \n        self.send_cost_report(cost_data, trends, recommendations)\n\n# Ejecutar análisis de costos\ncost_collector = CostMetricsCollector()\ncost_collector.run_cost_analysis()\n```",
    "security_metrics": "\n```python\n# Recolección de métricas de seguridad\nfrom azure.mgmt.security import SecurityCenter\nfrom azure.identity import DefaultAzureCredential\nfrom datetime import datetime\nimport json\n\nclass SecurityMetricsCollector:\n    def __init__(self):\n        self.credential = DefaultAzureCredential()\n        self.security_client = SecurityCenter(\n            self.credential, \n            subscription_id=\"your-subscription-id\"\n        )\n    \n    def collect_security_metrics(self):\n        # Recolecta métricas de seguridad\n        metrics = {\n            \"timestamp\": datetime.utcnow().isoformat(),\n            \"security_score\": self.get_security_score(),\n            \"compliance_status\": self.get_compliance_status(),\n            \"vulnerabilities\": self.get_vulnerabilities(),\n            \"security_alerts\": self.get_security_alerts(),\n            \"access_reviews\": self.get_access_reviews()\n        }\n        \n        return metrics\n    \n    def get_security_score(self):\n        # Obtiene puntuación de seguridad\n        try:\n            score = self.security_client.secure_scores.list()\n            return next(score).score\n        except:\n            return None\n    \n    def get_compliance_status(self):\n        # Obtiene estado de cumplimiento\n        try:\n            compliance = self.security_client.compliance.list()\n            return [item.as_dict() for item in compliance]\n        except:\n            return []\n    \n    def get_vulnerabilities(self):\n        # Obtiene vulnerabilidades detectadas\n        try:\n            vulnerabilities = self.security_client.assessments.list()\n            return [\n                {\n                    \"name\": v.display_name,\n                    \"status\": v.status.code,\n                    \"severity\": v.status.severity\n                }\n                for v in vulnerabilities\n                if v.status.code == \"Unhealthy\"\n            ]\n        except:\n            return []\n    \n    def get_security_alerts(self):\n        # Obtiene alertas de seguridad\n        try:\n            alerts = self.security_client.alerts.list()\n            return [\n                {\n                    \"name\": alert.alert_display_name,\n                    \"severity\": alert.severity,\n                    \"status\": alert.status\n                }\n                for alert in alerts\n            ]\n        except:\n            return []\n    \n    def get_access_reviews(self):\n        # Obtiene revisiones de acceso pendientes\n        try:\n            # Implementar lógica para obtener revisiones de acceso\n            return []\n        except:\n            return []\n    \n    def analyze_security_risks(self, metrics):\n        # Analiza riesgos de seguridad\n        risks = []\n        \n        # Análisis de puntuación de seguridad\n        if metrics[\"security_score\"] and metrics[\"security_score\"] < 70:\n            risks.append({\n                \"type\": \"low_security_score\",\n                \"score\": metrics[\"security_score\"],\n                \"severity\": \"high\",\n                \"description\": \"Security score below recommended threshold\"\n            })\n        \n        # Análisis de vulnerabilidades\n        high_severity_vulns = [\n            v for v in metrics[\"vulnerabilities\"] \n            if v[\"severity\"] == \"high\"\n        ]\n        \n        if high_severity_vulns:\n            risks.append({\n                \"type\": \"high_severity_vulnerabilities\",\n                \"count\": len(high_severity_vulns),\n                \"severity\": \"critical\",\n                \"description\": f\"Found {len(high_severity_vulns)} high severity vulnerabilities\"\n            })\n        \n        # Análisis de alertas de seguridad\n        critical_alerts = [\n            a for a in metrics[\"security_alerts\"] \n            if a[\"severity\"] == \"high\"\n        ]\n        \n        if critical_alerts:\n            risks.append({\n                \"type\": \"critical_security_alerts\",\n                \"count\": len(critical_alerts),\n                \"severity\": \"critical\",\n                \"description\": f\"Found {len(critical_alerts)} critical security alerts\"\n            })\n        \n        return risks\n    \n    def generate_security_recommendations(self, metrics, risks):\n        # Genera recomendaciones de seguridad\n        recommendations = []\n        \n        for risk in risks:\n            if risk[\"type\"] == \"low_security_score\":\n                recommendations.append({\n                    \"priority\": \"high\",\n                    \"action\": \"Review and implement security recommendations\",\n                    \"description\": \"Address security gaps to improve overall security score\"\n                })\n            \n            elif risk[\"type\"] == \"high_severity_vulnerabilities\":\n                recommendations.append({\n                    \"priority\": \"critical\",\n                    \"action\": \"Patch high severity vulnerabilities immediately\",\n                    \"description\": \"Prioritize fixing critical security vulnerabilities\"\n                })\n            \n            elif risk[\"type\"] == \"critical_security_alerts\":\n                recommendations.append({\n                    \"priority\": \"critical\",\n                    \"action\": \"Investigate and resolve security alerts\",\n                    \"description\": \"Address security incidents promptly\"\n                })\n        \n        return recommendations\n    \n    def send_security_report(self, metrics, risks, recommendations):\n        # Envía reporte de seguridad\n        report = {\n            \"timestamp\": datetime.utcnow().isoformat(),\n            \"metrics\": metrics,\n            \"risks\": risks,\n            \"recommendations\": recommendations\n        }\n        \n        # Enviar a sistema de alertas o dashboard\n        print(json.dumps(report, indent=2))\n    \n    def run_security_analysis(self):\n        # Ejecuta análisis completo de seguridad\n        print(\"Starting security analysis...\")\n        \n        metrics = self.collect_security_metrics()\n        risks = self.analyze_security_risks(metrics)\n        recommendations = self.generate_security_recommendations(metrics, risks)\n        \n        self.send_security_report(metrics, risks, recommendations)\n\n# Ejecutar análisis de seguridad\nsecurity_collector = SecurityMetricsCollector()\nsecurity_collector.run_security_analysis()\n```"
  },
  "roadmap_mejora": {
    "corto_plazo": [
      "Implementar monitoreo básico de recursos",
      "Configurar alertas de costo",
      "Establecer respaldos automáticos",
      "Implementar verificaciones de seguridad básicas"
    ],
    "mediano_plazo": [
      "Automatizar escalado de recursos",
      "Implementar análisis predictivo de costos",
      "Configurar dashboards avanzados",
      "Establecer flujos de trabajo de incidentes"
    ],
    "largo_plazo": [
      "Implementar IA/ML para optimización",
      "Automatización completa de operaciones",
      "Análisis avanzado de seguridad",
      "Optimización predictiva de recursos"
    ]
  },
  "kpis_mejora": {
    "rendimiento": [
      "Tiempo de respuesta promedio < 200ms",
      "Disponibilidad > 99.9%",
      "Throughput optimizado",
      "Latencia reducida en 20%"
    ],
    "costos": [
      "Reducción de costos en 15%",
      "Optimización de recursos en 25%",
      "Eliminación de recursos no utilizados",
      "Uso eficiente de Reserved Instances"
    ],
    "seguridad": [
      "Puntuación de seguridad > 90",
      "Cumplimiento 100%",
      "Tiempo de respuesta a incidentes < 1 hora",
      "Vulnerabilidades críticas = 0"
    ],
    "operaciones": [
      "Automatización del 80% de tareas",
      "Tiempo de despliegue < 30 minutos",
      "Recuperación ante desastres < 4 horas",
      "Disponibilidad del equipo 24/7"
    ]
  }
}